---
title: Dcoker系列11-Docker网络基本原理
author: ifuncat
date: 2021-06-08 21:20:22 +0800
categories: [Docker]
tags: [Docker]
---

### 一. Docker0网卡
- 准备工作: 方便初步学习, 清空宿主机上之前存在的docker镜像和容器, 命令如下: 
   
```bash
docker rm -f $(docker ps -aq)  ##先删除所有容器
docker rmi -f $(docker images -aq)   ##后删除所有镜像
```

- 清空完毕后执行 ip addr 命令得到如下结果, 可以看到存在三块网卡:
   - lo : 本机回环地址 127.0.0.1/8
   - en32 : 本机内网地址 192.168.245.147/24
   - docker0 : docker默认生成的网卡 172.17.0.1/16

<img src="https://cdn.jsdelivr.net/gh/ifuncat/blog-images/post/docker/docker11-1.png" width="90%">

- 查看docker0网络配置

<img src="https://cdn.jsdelivr.net/gh/ifuncat/blog-images/post/docker/docker11-2.png" width="90%">

### 二. Docker是如何处理容器间的网络访问

#### 1. 演示一: 查看docker容器的内部网络地址

- 可以看到容器启动后, 容器的内部存在一个网卡  4: eth0@if5 的 ip 地址 172.17.0.2

```bash
##运行一个tomcat容器, -d: 后台运行, -P 随机映射端口, --name 容器命名
docker run -d -P --name tomcat01 tomcat
##使用追加命令的形式
docker exec -it tomcat01 ip addr 

##输出如下
[root@localhost ~]# docker exec -it tomcat01 ip addr
1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
4: eth0@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default
    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0
    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0
       valid_lft forever preferred_lft forever
[root@localhost ~]#
```

#### 2. 演示二. 宿主机ping 通容器内部的ip地址

- 可以看到宿主机能够ping通tomcat01容器内部的ip

```bash
[root@localhost ~]# ping 172.17.0.2
PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.
64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.120 ms
64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.051 ms
```

#### 3. 演示三. 再次查看宿主机的网卡情况

- 可以发现, 启动容器后多了一块网卡 5: veth894e1c7@if4 

<img src="https://cdn.jsdelivr.net/gh/ifuncat/blog-images/post/docker/docker11-3.png" width="90%">

#### 4. 演示四. 启动新的一个容器, 查看宿主机和容器内部的网络情况

- 启动命令: docker run -d -P --name tomcat02 tomcat
- 发现宿主机又多个一个网卡 7: vethc75976c@if6, 容器内部的网卡:  6: eth0@if7
- 可以发现宿主机新增的网卡和容器内的网卡是成对出现的 7: vethc75976c@if6  <-> 6: eth0@if7

<img src="https://cdn.jsdelivr.net/gh/ifuncat/blog-images/post/docker/docker11-4.png" width="90%">

#### 5. 演示五. 两个容器间ping通

```bash
##172.17.0.2为tomcat01的ip
[root@localhost ~]# docker exec -it tomcat02 ping 172.17.0.2
PING 172.17.0.2 (172.17.0.2) 56(84) bytes of data.
64 bytes from 172.17.0.2: icmp_seq=1 ttl=64 time=0.073 ms
64 bytes from 172.17.0.2: icmp_seq=2 ttl=64 time=0.057 ms
```

### 三. 原理分析及结论

- 只要安装了docker就会有一个网卡docker0
- 每启动一个docker容器, docker都会给这个容器分配一个ip, 类如上述的tomcat01容器的ip 172.17.0.2
- 可以发现宿主机新增的网卡和容器内的网卡是成对出现的, 如tomcat02容器: **7: vethc75976c@if6**  <-> **6: eth0@if7**
- 这对网卡一端连着协议, 一段彼此相连, 使用的是 [ veth-pair 技术](https://www.cnblogs.com/bakari/p/10613710.html), veth-pair充当桥梁, 连接各种虚拟网络设备
- 删除容器后, 这个容器对应的一对网卡就会被删除.
- 容器间以docker0作为桥接, docker0相当于一个路由器, 实现docker容器间的网络请求, 如上述的tomcat02 ping 通 tomat01

<img src="https://cdn.jsdelivr.net/gh/ifuncat/blog-images/post/docker/docker11-5.png" width="70%">

- 不指定网络的情况下, 容器都是docker0 路由, docker会给容器分配一个默认的可用ip, 最大ip个数为 65535, 计算方法:如255.255.0.1/16, 16代表两段, 一段8位, 2^8*2^8- 1 排除255.255.255.255
- docker使用的是Linux的veth-pair桥接, docker0 作为容器的网桥
- docker中的所有网络接口都是虚拟的, 因为虚拟的转发效率更高

<img src="https://cdn.jsdelivr.net/gh/ifuncat/blog-images/post/docker/docker11-6.png" width="70%">
